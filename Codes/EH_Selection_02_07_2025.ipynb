{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dae7f4ff-c60b-4f32-a660-e4a2d69c4a35",
   "metadata": {},
   "source": [
    "# The next block of code install the necessary packages required for the homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bed9e5a4-6859-4b1b-9554-03cafdcba3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\egyin\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\egyin\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\egyin\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: mlxtend in c:\\users\\egyin\\anaconda3\\lib\\site-packages (0.23.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\egyin\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\egyin\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\egyin\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\egyin\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\egyin\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\egyin\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\egyin\\anaconda3\\lib\\site-packages (from mlxtend) (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\egyin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\egyin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\egyin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\egyin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\egyin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\egyin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\egyin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\egyin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas scikit-learn mlxtend\n",
    "#numpy – for numerical operations.\n",
    "#pandas – for data manipulation and analysis.\n",
    "#scikit-learn – for machine learning tasks, including model creation and data splitting.\n",
    "#mlxtend – for advanced machine learning utilities, specifically the SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47cce1f-b8d9-497c-8b55-7a6ea32d5bfa",
   "metadata": {},
   "source": [
    "#The next block of code imports the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53a435b6-ab2b-4994-bfaa-424761775299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np             #library for data manipulation\n",
    "import pandas as pd            #library for data manipulation\n",
    "from sklearn.ensemble import RandomForestClassifier    #RandomForestClassifier for the model\n",
    "from sklearn.model_selection import train_test_split   #train_test_split to split the dataset\n",
    "from sklearn.metrics import accuracy_score as acc      #accuracy_score to measure performance\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs   #SequentialFeatureSelector for step-forward feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507bc8ef-a96e-42c1-8774-701a0dfdf8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next block of code reads the wine-quality dataset from the Raw folder within the Data Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fd86dd8-b956-4d58-bb62-52a85c992192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully from: ..\\Data\\Raw\\winequality-white.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the file path relative to the Codes directory\n",
    "data_folder = os.path.join('..', 'Data', 'Raw')  # Go up one directory from Codes, then navigate to Data/Raw\n",
    "file_name = 'winequality-white.csv'\n",
    "file_path = os.path.join(data_folder, file_name)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Print confirmation\n",
    "print(\"Dataset loaded successfully from:\", file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3308b99b-2aa7-44ec-b009-733c4dd74f5e",
   "metadata": {},
   "source": [
    "#The next block of code provides a descriptive statistics set of the wine quality dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b09d3c-4502-4e89-a8ed-7b8245ff43c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully from: ..\\Data\\Raw\\winequality-white.csv\n",
      "Descriptive statistics saved to: ..\\Results\\EH_Description_02_07_2025.csv\n"
     ]
    }
   ],
   "source": [
    "import os          # For handling file paths and directories\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "\n",
    "data_folder = os.path.join('..', 'Data', 'Raw')  # Relative path to the Raw data folder by navigating up one directory (..)\n",
    "file_name = 'winequality-white.csv'              \n",
    "\n",
    "# Combine the folder path and file name to create the full file path\n",
    "file_path = os.path.join(data_folder, file_name)\n",
    "\n",
    "df = pd.read_csv(file_path, sep=';')\n",
    "print(\"Dataset loaded successfully from:\", file_path)\n",
    "\n",
    "# Provides summary statistics such as count, mean, standard deviation, min, max, etc for each numeric column in the dataset.\n",
    "description = df.describe()\n",
    "\n",
    "#Output path where the descriptive statistics will be saved by navigating one directory up from Codes to the Results folder.\n",
    "output_folder = os.path.join('..', 'Results')\n",
    "os.makedirs(output_folder, exist_ok=True)  # Create the Results folder if it doesn't already exist\n",
    "\n",
    "# Step 6: Define the file name for saving the descriptive statistics by following the class naming convention\n",
    "output_file_name = 'EH_Description_02_07_2025.csv'\n",
    "output_file_path = os.path.join(output_folder, output_file_name)\n",
    "\n",
    "# Saving the DataFrame `description` to the specified CSV file.\n",
    "description.to_csv(output_file_path)\n",
    "\n",
    "# Printing the confirmation of successful save\n",
    "print(\"Descriptive statistics saved to:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021f1bfc-dd70-4106-99b7-39a54451764e",
   "metadata": {},
   "source": [
    "#The next block of code split the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94a27a8f-c498-4a95-b473-25034083f33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.values[:, :-1],    # All columns except the last (features)\n",
    "    df.values[:, -1],     # The last column (target: 'quality')\n",
    "    test_size=0.25,       # 25% of data for testing\n",
    "    random_state=42       # Seed to ensure consistent results\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d192985a-ba9e-4794-867e-943ba6c971ca",
   "metadata": {},
   "source": [
    "#The next block of code flatten the Target Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bcf860f-4a4c-4bcc-899d-5f088b2fc23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b94ac1-60dd-4a96-9948-66b9a5a89130",
   "metadata": {},
   "source": [
    "#The next block of code prints the Dataset Shapes-This helps to verify that the dataset has been split correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ae6717b-362c-4831-a4ea-0c9881c75eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (3673, 11) (3673,)\n",
      "Testing dataset shape: (1225, 11) (1225,)\n"
     ]
    }
   ],
   "source": [
    "print('Training dataset shape:', X_train.shape, y_train.shape)\n",
    "print('Testing dataset shape:', X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3777f8-1223-4f3f-86c8-8116c52a4b61",
   "metadata": {},
   "source": [
    "#The next block of codes is about using Feature Selection of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01d64dd2-8ff4-47d1-ab6a-c80153a5d81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[2025-02-07 11:19:27] Features: 1/5 -- score: 0.49577304491278806\n",
      "[2025-02-07 11:19:43] Features: 2/5 -- score: 0.5428842054532985\n",
      "[2025-02-07 11:19:57] Features: 3/5 -- score: 0.6044034180429666\n",
      "[2025-02-07 11:20:10] Features: 4/5 -- score: 0.6272694581919962\n",
      "[2025-02-07 11:20:21] Features: 5/5 -- score: 0.6387054440304732"
     ]
    }
   ],
   "source": [
    "# Build RF classifier to use in feature selection\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "# Explanation:\n",
    "# - Creates a Random Forest classifier with 100 trees.\n",
    "# - n_jobs=-1 allows the use of all available CPU cores for parallel processing.\n",
    "\n",
    "# Build step forward feature selection\n",
    "sfs1 = sfs(\n",
    "    clf,                # Classifier to use for feature evaluation\n",
    "    k_features=5,       # Selects 5 features\n",
    "    forward=True,       # Step forward feature selection\n",
    "    floating=False,     # Disables floating selection\n",
    "    verbose=2,          # Outputs detailed logs of the selection process\n",
    "    scoring='accuracy', # Uses accuracy to evaluate subsets\n",
    "    cv=5                # 5-fold cross-validation for validation\n",
    ")\n",
    "\n",
    "# Explanation:\n",
    "# - The feature selection process aims to find the best 5 features using forward selection.\n",
    "# - It validates each subset using cross-validation and accuracy scoring.\n",
    "\n",
    "# Perform SFFS (Sequential Forward Feature Selection)\n",
    "sfs1 = sfs1.fit(X_train, y_train)\n",
    "\n",
    "# Explanation:\n",
    "# - Trains the feature selector using the training data.\n",
    "# - Iteratively evaluates different subsets to determine the optimal set of 5 features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aedf373-baae-4ab2-a1c1-36dec4e8bd4e",
   "metadata": {},
   "source": [
    "#The next block of code extract and display the 5 Selected Feature indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74c6c670-9eb6-4d97-b4e9-c37922cb080c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected feature indices: [1, 3, 5, 7, 10]\n"
     ]
    }
   ],
   "source": [
    "# Extract and print the selected feature indices\n",
    "feat_cols = list(sfs1.k_feature_idx_)\n",
    "print(\"Selected feature indices:\", feat_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34d5f08-fcf2-471d-974e-763a3251ab49",
   "metadata": {},
   "source": [
    "#The next block of code evaluates the Full Model Using the 5 Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a628eba-1a5e-4a0f-9fd4-12da9d644818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy on selected features: 0.562\n",
      "Testing accuracy on selected features: 0.519\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest Classifier with the specified parameters\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=1000,  # Number of trees in the random forest\n",
    "    random_state=42,    # Random state for reproducibility\n",
    "    max_depth=4         # Maximum depth of the decision trees to prevent overfitting\n",
    ")\n",
    "\n",
    "# Train the classifier using only the selected features\n",
    "clf.fit(X_train[:, feat_cols], y_train)\n",
    "\n",
    "# Make predictions on the training data using the selected features\n",
    "y_train_pred = clf.predict(X_train[:, feat_cols])\n",
    "\n",
    "# Calculate and print the training accuracy\n",
    "print('Training accuracy on selected features: %.3f' % acc(y_train, y_train_pred))\n",
    "\n",
    "# Make predictions on the test data using the selected features\n",
    "y_test_pred = clf.predict(X_test[:, feat_cols])\n",
    "\n",
    "# Calculate and print the testing accuracy\n",
    "print('Testing accuracy on selected features: %.3f' % acc(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b726d050-dd9b-4c88-a202-a13f3ce2ffec",
   "metadata": {},
   "source": [
    "#The testing accuracy obtained with 5 features is 0.519 as seen from above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdb53ed-1cf4-418a-b76e-0f98262764da",
   "metadata": {},
   "source": [
    "#The next block evaluates the full model on ALL features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09c8bcf9-9457-4be0-a5e0-89238cf11a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy on all features: 0.566\n",
      "Testing accuracy on all features: 0.509\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=1000,   # Use 1000 trees in the forest\n",
    "    random_state=42,     # Random state ensures results are reproducible\n",
    "    max_depth=4          # Limit tree depth to prevent overfitting\n",
    ")\n",
    "\n",
    "# Train the model on the full feature set\n",
    "clf.fit(X_train, y_train)  # Train the classifier using all features in X_train\n",
    "\n",
    "# Make predictions on the training dataset\n",
    "y_train_pred = clf.predict(X_train)  # Predict the training labels using the full feature set\n",
    "\n",
    "# Evaluate training accuracy\n",
    "print('Training accuracy on all features: %.3f' % acc(y_train, y_train_pred))\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "y_test_pred = clf.predict(X_test)  # Predict the test labels using all features\n",
    "\n",
    "# Evaluate testing accuracy\n",
    "print('Testing accuracy on all features: %.3f' % acc(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9032000-e467-4a4d-88d9-6f77d4a8d21a",
   "metadata": {},
   "source": [
    "#The next block of code modifies Feature Selection to Use k_features=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82e729a1-44c4-4a71-a731-37db6e7a4f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[2025-02-07 11:23:11] Features: 1/6 -- score: 0.4927798476338764\n",
      "[2025-02-07 11:23:27] Features: 2/6 -- score: 0.5450629298040742\n",
      "[2025-02-07 11:23:42] Features: 3/6 -- score: 0.6060394075886485\n",
      "[2025-02-07 11:23:53] Features: 4/6 -- score: 0.6275489814454392\n",
      "[2025-02-07 11:24:05] Features: 5/6 -- score: 0.6389786650354965\n",
      "[2025-02-07 11:24:15] Features: 6/6 -- score: 0.642520157926931"
     ]
    }
   ],
   "source": [
    "# Build RF classifier to use in feature selection\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "# Explanation:\n",
    "# - Creates a Random Forest classifier with 100 trees.\n",
    "# - n_jobs=-1 allows the use of all available CPU cores for parallel processing.\n",
    "\n",
    "# Build step forward feature selection\n",
    "sfs1 = sfs(\n",
    "    clf,                   # Classifier to use for feature evaluation\n",
    "    k_features=6,          # Selects 6 features (modified from 5)\n",
    "    forward=True,          # Step forward feature selection\n",
    "    floating=False,        # Disables floating selection\n",
    "    verbose=2,             # Outputs detailed logs of the selection process\n",
    "    scoring='accuracy',    # Uses accuracy to evaluate subsets\n",
    "    cv=5                   # 5-fold cross-validation for validation\n",
    ")\n",
    "\n",
    "# Explanation:\n",
    "# - The feature selection process aims to find the best 6 features using forward selection.\n",
    "# - It validates each subset using cross-validation and accuracy scoring.\n",
    "\n",
    "# Perform SFFS (Sequential Forward Feature Selection)\n",
    "sfs1 = sfs1.fit(X_train, y_train)\n",
    "\n",
    "# Explanation:\n",
    "# - Trains the feature selector using the training data.\n",
    "# - Iteratively evaluates different subsets to determine the optimal set of 6 features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc74589-9349-4723-8c2b-640a0d6cdac5",
   "metadata": {},
   "source": [
    "#The next block of code extract and display the 6 Selected Feature indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bd0f879-3374-4e48-83ce-3e7cb7a0c1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected feature indices with 6 features: [0, 1, 3, 6, 7, 10]\n"
     ]
    }
   ],
   "source": [
    "feat_cols = list(sfs1.k_feature_idx_)\n",
    "print(\"Selected feature indices with 6 features:\", feat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca4c6a08-9037-4535-8d6a-18dbdfe32bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next block of code evaluates the Full Model Using the 6 Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64997a31-686f-4084-a286-36fb96924492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy on selected features: 0.561\n",
      "Testing accuracy on selected features: 0.511\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest Classifier with the specified parameters\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=1000,   # Use 1000 trees in the forest\n",
    "    random_state=42,     # Ensures reproducibility\n",
    "    max_depth=4          # Limits tree depth to prevent overfitting\n",
    ")\n",
    "\n",
    "# Train the classifier on the 6 selected features\n",
    "clf.fit(X_train[:, feat_cols], y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = clf.predict(X_train[:, feat_cols])\n",
    "\n",
    "# Evaluate and print training accuracy\n",
    "train_accuracy = acc(y_train, y_train_pred)\n",
    "print('Training accuracy on selected features: %.3f' % train_accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = clf.predict(X_test[:, feat_cols])\n",
    "\n",
    "# Evaluate and print testing accuracy\n",
    "test_accuracy = acc(y_test, y_test_pred)\n",
    "print('Testing accuracy on selected features: %.3f' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d2191-eef3-40d9-8a68-c4145c958e1c",
   "metadata": {},
   "source": [
    "#The testing accuracy obtained with 6 features is 0.511 as seen from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e843e4a-d97b-493b-b10d-468ec3ac19d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
